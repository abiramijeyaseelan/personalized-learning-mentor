{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1MyuUygFibY"
      },
      "outputs": [],
      "source": [
        "# Personalized Learning Mentor using Large Language Models\n",
        "\n",
        "AI Applications – Individual Open Project\n",
        "Module E\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Problem Definition & Objective\n",
        "\n",
        "### Selected Project Track\n",
        "LLM-based AI Application\n",
        "\n",
        "### Problem Statement\n",
        "Students preparing for exams require personalized explanations based on their learning purpose such as theory understanding, exam preparation, or MCQ practice. Traditional learning systems provide static content that does not adapt to individual needs.\n",
        "\n",
        "### Objective\n",
        "The objective of this project is to design a Personalized Learning Mentor using a conversational Large Language Model that dynamically adapts explanations based on user intent.\n",
        "\n",
        "### Real-World Relevance\n",
        "This system is applicable in EdTech platforms, online tutoring systems, self-learning portals, and AI-powered academic assistants.\n"
      ],
      "metadata": {
        "id": "CmobXgaPNmSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Data Understanding & Preparation\n",
        "\n",
        "This project does not use a traditional dataset.\n",
        "\n",
        "### Data Source\n",
        "- User input text (learning purpose, subject, depth)\n",
        "- Prompt templates designed for the LLM\n",
        "\n",
        "### Data Processing\n",
        "- User inputs are structured into prompts\n",
        "- No missing values or noise handling is required\n"
      ],
      "metadata": {
        "id": "WbQhjyp2Nqbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Model / System Design\n",
        "\n",
        "### AI Technique Used\n",
        "- Large Language Models (LLMs)\n",
        "- Conversational AI\n",
        "- Prompt Engineering\n",
        "\n",
        "### Model Used\n",
        "Meta-LLaMA-3-8B-Instruct (Chat-based model)\n",
        "\n",
        "### System Architecture\n",
        "User Input → Prompt Engineering → Chat-based LLM → Personalized Output\n",
        "\n",
        "### Design Justification\n",
        "Chat-based LLMs are ideal for adaptive learning because they can maintain context, adjust explanation depth, and generate human-like responses.\n"
      ],
      "metadata": {
        "id": "OQbGyX0INtzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Placeholder token for demonstration\n",
        "HF_TOKEN = \"YOUR_HF_TOKEN\"\n",
        "\n",
        "client = InferenceClient(token=HF_TOKEN)\n",
        "\n",
        "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "def personalized_teach(prompt):\n",
        "    \"\"\"\n",
        "    Generates personalized learning content using a chat-based LLM.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a personalized learning mentor.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=400,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example prompt (API call disabled for evaluation)\n",
        "example_prompt = \"Explain Control Systems for exam preparation\"\n",
        "# personalized_teach(example_prompt)\n"
      ],
      "metadata": {
        "id": "P2VSwDUXNxmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Prompt Engineering\n",
        "\n",
        "Prompt structure dynamically changes based on:\n",
        "- Learning purpose (theory / exam / MCQ)\n",
        "- Subject or topic\n",
        "- Explanation depth\n",
        "\n",
        "### Example Prompt\n",
        "\"Explain Control Systems for exam preparation with clear theory and examples.\"\n",
        "\n",
        "Prompt engineering enables personalized and adaptive responses.\n"
      ],
      "metadata": {
        "id": "t6IwDo7TN0Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Evaluation & Analysis\n",
        "\n",
        "### Evaluation Method\n",
        "Qualitative evaluation based on:\n",
        "- Relevance of explanation\n",
        "- Alignment with learning purpose\n",
        "- Clarity and coherence\n",
        "\n",
        "### Sample Output\n",
        "Outputs generated by the deployed Hugging Face Space demonstrate accurate and personalized explanations.\n"
      ],
      "metadata": {
        "id": "yIDeRLkvN26K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Conclusion & Future Scope\n",
        "\n",
        "This project demonstrates how chat-based LLMs can be used for personalized learning.\n",
        "\n",
        "### Future Improvements\n",
        "- MCQ evaluation with scoring\n",
        "- Document upload for personalized tutoring\n",
        "- Progress tracking dashboard\n"
      ],
      "metadata": {
        "id": "f6mGldZFN3cy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}